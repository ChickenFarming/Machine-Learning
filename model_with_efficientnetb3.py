# -*- coding: utf-8 -*-
"""Model with EfficientNetB3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jEukWVB_cMC5ZfflRmlnKrO3MfqjWy_y

# Load Library
"""

import os
import time
import shutil
import pathlib
import itertools
import cv2
import numpy as np
import pandas as pd
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam, Adamax
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization
from tensorflow.keras import regularizers

# Ignore Warnings
import warnings
warnings.filterwarnings("ignore")

print ('modules loaded')

"""# Path Directory"""

from google.colab import drive
drive.mount('/content/drive')

data_dir = '/content/drive/MyDrive/PROJECT CAPSTONE/Train'
csv_dir = '/content/drive/MyDrive/PROJECT CAPSTONE/train_data.csv'

"""# Split Data"""

def split_data(data_dir, csv_dir):
    df = pd.read_csv(csv_dir)
    df.columns = ['filepaths', 'labels']
    df['filepaths'] = df['filepaths'].apply(lambda x: os.path.join(data_dir, x))
    nama_penyakit = df['labels']
    train_df, dummy_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42, stratify=nama_penyakit)
    nama_penyakit = dummy_df['labels']
    valid_df, test_df = train_test_split(dummy_df, train_size=0.5, shuffle=True, random_state=123, stratify=nama_penyakit)

    return train_df, valid_df, test_df

train_df, valid_df, test_df = split_data(data_dir, csv_dir)

"""# Data Generator"""

def create_generator(df, batch_size, class_mode, target_size):
    datagen = ImageDataGenerator(rescale=1.0/255.)

    generator = datagen.flow_from_dataframe(df,
                                            x_col='filepaths',
                                            y_col='labels',
                                            batch_size=batch_size,
                                            class_mode=class_mode,
                                            target_size=target_size)

    return generator

train_generator = create_generator(train_df, batch_size=25, class_mode='categorical', target_size=(224, 224))
validation_generator = create_generator(valid_df, batch_size=25, class_mode='categorical', target_size=(224, 224))
test_generator = create_generator(test_df, batch_size=25, class_mode='categorical', target_size=(224, 224))

"""# Model"""

#model 1
def create_model():
  model = tf.keras.models.Sequential([
    tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights="imagenet", input_shape=(224, 224, 3), pooling='max'),
    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),
    Dense(215, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),
          bias_regularizer=regularizers.l1(0.006), activation='relu'),
    Dropout(rate=0.35, seed=123),
    Dense(4, activation='softmax')
  ])

  model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),
                loss='categorical_crossentropy', metrics=['accuracy'])

  return model

batch_data, batch_labels = next(train_generator)
print("Shape of batch data:", batch_data.shape)
print("Shape of batch labels:", batch_labels.shape)

model = create_model()

history = model.fit(train_generator,
                    epochs=15,
                    verbose=1,
                    validation_data=validation_generator,
                    validation_steps= None,
                    shuffle= False)